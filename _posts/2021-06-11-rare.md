---
title : "[Review] Robust Scene Text Recognition with Automatic Rectification"
excerpt: "rectifying image and attention-based recognizer"
toc: true
header:
  overlay_image : /assets/images/overlay_image.jpg
  teaser: /assets/images/teaser_cv.jpg
---
# Intuition
- words in natural images often possess irregular shapes   <br>
&#8594; rectifying images would facilitate the task for the text recognizer

# Model Structure
1. Spatial Transformer Network(STN)
2. Sequence Recognition Network(SRN)
<p align="center">
  <img src="/assets/images/posts/RARE/overall_architecture.png">
</p>

# STN
- performs Thin-Plate-Spline(TPS) transformation to rectify the input image
<p align="center">
  <img src="/assets/images/posts/RARE/STN.png">
</p>
## Localization & Grid Generator
- localizes K number, K is an even number, of fiducial points using CNN
- fiducial points are needed in order to find mapping before the original image and the rectified image
- defines another K number of points called base fiducial points
- base fiducial points are place on top and below of the text in order to define the transformation in between image and the rectified image

# SRN
<p align="center">
  <img src="/assets/images/posts/RARE/SRN.png">
</p>
- extracts a sequential representation from rectified image, I', and recognizes sequence of characters 
- attention-based model consists of an encoder and a decoder

## Encoder
- extracts sequential representation from the input image, I'
- combination of convolutional layers and recurrent networks
- uses CNN to extract each local image patch
- takes out the columns of the features maps in the left-to-right order and flattens them into vectors via so called "map-to-sequence" operation
- lastly apply two-layer Bidirectional Long-Short Term Memory to model long-term dependencies

## Decoder
<p align="center">
  <img src="/assets/images/posts/RARE/decoder.png">
</p>
- recurrently generates a sequence conditioned on the sequential representation via Gated Recurrent Unit
- however, rather than directly uses previous output vector, it uses attention module to augment a vector for the next time step 




<!--
<p align="center">
  <img src="/assets/images/posts/SRN/GSRM.png"/>
</p>
-->






