---
title : "[Review] Towards Accurate Scene Text Recognition with Semantic Reasoning Networks"
excerpt: "Global semantic information and parallel attention modules"
toc: true
header:
  overlay_image : /assets/images/overlay_image.jpg
---
# Intuition
- Scene Text Recognition에서 주로 사용되는 것은 RNN-based model  <br>
&#8594; time-dependent하다는 단점 존재
- Semantic information을 고려하는 경우에도 대부분 one-way serial transmission을 사용   <br>
&#8594; 정보손실 및 error accumulation 문제 발생 가능성 존재   <br>
- 따라서 이 논문에서는 global semantic 정보를 고려하면서 위의 단점들을 해결하려고 노력함

# Model Structure
1. ResNet50 + FPN (Backbone)
2. Parallel Visual Attention Module (PVAM)
3. Global Semantic Reasoning Module (GSRM)
4. Visual-Semantic Fusion Decoder (VSFD)
<p align="center">
  <img src="/assets/images/posts/SRN/overall_structure.png" />
</p>

# Backbone
- ResNet50
- FPN을 사용해서 여러 stage의 hierarchical features들을 종합적으로 판단

# PVAM 
- 이전 Attention Module에 time-dependent한 $$H_t$$가 단점으로 작용함
<p align="center">
  <img src="/assets/images/posts/SRN/PVAM1.png" />
</p>
- 예시로, Badhandu Attention에서 사용된 time-dependent $$H_t$$의 경우 각각의 $$H_{t-1}$$이 필요하여 병철처리하는 것이 불가능 하였는데, 이를 time-independent character reading order $$O_t$$로 대체함으로써 Attention Module들을 병렬처리할수 있도록함
<p align="center">
  <img src="/assets/images/posts/SRN/PVAM2.png" />
</p>
- 그 후 위의 결과들을 이용하여 Aligned Visual Features $$G$$를 생생함

# GSRM
1. Visual-to-Semantic Embedding Block
2. Global Semantic Reasoning Block
<p align="center">
  <img src="/assets/images/posts/SRN/GSRM.png"  />
</p>
## Visual-to-Semantic Embedding Block
- 위의 그림에서 볼수 있듯 visual-to-semantic embedding block의 목적은 $$e'$$을 계산하는 것임
- 이전 단계인 PVAM에서 계산된 Aligned Visual Features $$G$$가 fc layer, argmax, embedding을 차례로 거치며 $$e'_1,\ \cdots \ ,e'_N$$를 계산하게 됨.
- 여기서 각각의 $$e'_i$$는 estimated 된 word embedding $$e_i$$를 의미함

## Global Semantic Reasoning Block 
- semantic reasoning block의 목적은 transformer module을 활용하여, global semantic information을 가지는 $$S$$를 계산하는 것임
- 이 부분도 병렬처리가 가능하여, 속도 향상에 기여하고있음

# Visual-Semantic Fusion Decoder
- 여러 module을 거치며 visual aligned features $$G$$와 global semantic information $$S$$가 계산되었음
- 따라서, visual-semantic fusion decoder의 목적은 visual information과 semantic information을 취합하여, 주어진 정보를 decoding하는 것임 
<p align="center"> 
  <img src="/assets/images/posts/SRN/VSFD.png" />
</p>
- $$G$$와 $$S$$의 경우 domain이 다르기떄문에, 결합된 결과인 $$f_t$$를 계산하는 과정에서 weight를 사용함
- $$f_t, t\in [1,\cdots, N]$$에서의 값들은 각각character의 예측값을 의미함   

# Reference
[Towards Accurate Scene Text Recognition with Semantic Reasoning Networks](https://arxiv.org/pdf/2003.12294.pdf)

<!-- to change the font size, look at _page.scss, then search .page__content, line 110 - 112 --> 








